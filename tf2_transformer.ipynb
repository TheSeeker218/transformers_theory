{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhobRF-oT2aK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f13BP1j6T6uV"
      },
      "source": [
        "# Transformer Theory and Implementations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m-vg8jQYUCHF",
        "outputId": "84915402-08c9-47c8-ffed-59cdcad65e56"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQE2oSS2XGXk"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBB02hKMXFkG"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "raw_data = (\n",
        "    ('What a ridiculous concept!', 'Quel concept ridicule !'),\n",
        "    ('Your idea is not entirely crazy.', \"Votre idée n'est pas complètement folle.\"),\n",
        "    (\"A man's worth lies in what he is.\", \"La valeur d'un homme réside dans ce qu'il est.\"),\n",
        "    ('What he did is very wrong.', \"Ce qu'il a fait est très mal.\"),\n",
        "    (\"All three of you need to do that.\", \"Vous avez besoin de faire cela, tous les trois.\"),\n",
        "    (\"Are you giving me another chance?\", \"Me donnez-vous une autre chance ?\"),\n",
        "    (\"Both Tom and Mary work as models.\", \"Tom et Mary travaillent tous les deux comme mannequins.\"),\n",
        "    (\"Can I have a few minutes, please?\", \"Puis-je avoir quelques minutes, je vous prie ?\"),\n",
        "    (\"Could you close the door, please?\", \"Pourriez-vous fermer la porte, s'il vous plaît ?\"),\n",
        "    (\"Did you plant pumpkins this year?\", \"Cette année, avez-vous planté des citrouilles ?\"),\n",
        "    (\"Do you ever study in the library?\", \"Est-ce que vous étudiez à la bibliothèque des fois ?\"),\n",
        "    (\"Don't be deceived by appearances.\", \"Ne vous laissez pas abuser par les apparences.\"),\n",
        "    (\"Excuse me. Can you speak English?\", \"Je vous prie de m'excuser ! Savez-vous parler anglais ?\"),\n",
        "    (\"Few people know the true meaning.\", \"Peu de gens savent ce que cela veut réellement dire.\"),\n",
        "    (\"Germany produced many scientists.\", \"L'Allemagne a produit beaucoup de scientifiques.\"),\n",
        "    (\"Guess whose birthday it is today.\", \"Devine de qui c'est l'anniversaire, aujourd'hui !\"),\n",
        "    (\"He acted like he owned the place.\", \"Il s'est comporté comme s'il possédait l'endroit.\"),\n",
        "    (\"Honesty will pay in the long run.\", \"L'honnêteté paye à la longue.\"),\n",
        "    (\"How do we know this isn't a trap?\", \"Comment savez-vous qu'il ne s'agit pas d'un piège ?\"),\n",
        "    (\"I can't believe you're giving up.\", \"Je n'arrive pas à croire que vous abandonniez.\"),\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M-PeicQXRyu"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVfxXawSXVLZ"
      },
      "source": [
        "raw_data_en, raw_data_fr = list(zip(*raw_data))\n",
        "raw_data_en, raw_data_fr = list(raw_data_en), list(raw_data_fr)\n",
        "\n",
        "raw_data_en = [normalize_string(data) for data in raw_data_en]\n",
        "raw_data_fr_in = ['<start> ' + normalize_string(data) for data in raw_data_fr]\n",
        "raw_data_fr_out = [normalize_string(data) + ' <end>' for data in raw_data_fr]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQcf7nT9XdZG"
      },
      "source": [
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "en_tokenizer.fit_on_texts(raw_data_en)\n",
        "data_en = en_tokenizer.texts_to_sequences(raw_data_en)\n",
        "\n",
        "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,\n",
        "                                                        padding='post')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6El2Nz-0Xf4m"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRA_IO9bXvOG"
      },
      "source": [
        "fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "fr_tokenizer.fit_on_texts(raw_data_fr_in)\n",
        "fr_tokenizer.fit_on_texts(raw_data_fr_out)\n",
        "\n",
        "data_fr_in = fr_tokenizer.texts_to_sequences(raw_data_fr_in)\n",
        "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in,\n",
        "                                                           padding='post')\n",
        "\n",
        "data_fr_out = fr_tokenizer.texts_to_sequences(raw_data_fr_out)\n",
        "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out,\n",
        "                                                            padding='post')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHKp96SkXmjL"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (data_en, data_fr_in, data_fr_out))\n",
        "dataset = dataset.shuffle(20).batch(5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41PFiSzSU9dD"
      },
      "source": [
        "## Encoder Components\n",
        "- Embedding\n",
        "- Positional Encoding\n",
        "- Multi-Head Attention\n",
        "- Position wise FFN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZU_xuijVYuU"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pu3yuBXUCRn"
      },
      "source": [
        "def positional_embedding(pos,model_size):\n",
        "  PE = np.zeros((1,model_size))\n",
        "\n",
        "  for i in range(model_size):\n",
        "    if i%2 == 0:\n",
        "      PE[:,i] = np.sin(pos/10000**(i/model_size))\n",
        "    else:\n",
        "      PE[:,i] = np.cos(pos/10000**((i-1)/model_size))\n",
        "\n",
        "  return PE\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtnpeeqaUCTx"
      },
      "source": [
        "max_length = max(len(data_en[0]),len(data_fr_in[0]))\n",
        "MODEL_SIZE = 128\n",
        "\n",
        "pes = []\n",
        "\n",
        "for i in range(max_length):\n",
        "  pes.append(positional_embedding(i,MODEL_SIZE))\n",
        "\n",
        "pes = np.concatenate(pes,axis =0)\n",
        "pes = tf.constant(pes,dtype=tf.float32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRDgH9VUb8Xn"
      },
      "source": [
        "### Multihead Attention\n",
        "- Source sequence pays attention to itself (Encoder’s self attention)\n",
        "- Target sequence pays attention to itself (Decoder’s self attention)\n",
        "- Target sequence pays attention to source sequence (same as Seq2Seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ADGzwrhcNqd"
      },
      "source": [
        "- Query: the one which pays attention\n",
        "- (Key, Value): the one to which attention is drawn. Key and value are exactly the same within this post."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig7uMK9UY8Yw"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.Model):\n",
        "  def __init__(self,model_size,h):\n",
        "    # h = head size\n",
        "    super(MultiHeadAttention,self).__init__()\n",
        "    self.query_size = model_size//h\n",
        "    self.key_size = model_size//h\n",
        "    self.value_size = model_size//h\n",
        "    self.h = h\n",
        "    self.wq = [tf.keras.layers.Dense(self.query_size) for _ in range(h)]\n",
        "    self.wk = [tf.keras.layers.Dense(self.key_size) for _ in range(h)]\n",
        "    self.wv = [tf.keras.layers.Dense(self.value_size) for _ in range(h)]\n",
        "    self.wo = tf.keras.layers.Dense(model_size)\n",
        "  def call(self,query,value):\n",
        "\n",
        "    # shapes (batch,query_len,model_size)\n",
        "    heads = []\n",
        "    for i in range(self.h):\n",
        "      score = tf.matmul(self.wq[i](query),self.wk[i](value),transpose_b = True)/tf.math.sqrt(tf.dtypes.cast(self.key_size,tf.float32))\n",
        "      alignment = tf.nn.softmax(score,axis =2)\n",
        "      head = tf.matmul(alignment,self.wv[i](value))\n",
        "      heads.append(head)\n",
        "    heads = tf.concat(heads, axis=2)\n",
        "    heads = self.wo(heads)\n",
        "    return heads\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsaIebOOgFDj"
      },
      "source": [
        "### Encoder Blocks\n",
        "- One Embedding layer\n",
        "- One or many layers, each layer contains:\n",
        "  - One Multi-Head Attention block\n",
        "  - One Normalization layer for Attention block\n",
        "  - One Feed-Forward Network block\n",
        "  - One Normalization layer for FFN block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wYGLibZgP27"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,model_size,num_layers,h):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.model_size = model_size\n",
        "    self.num_layers = num_layers\n",
        "    self.h = h\n",
        "\n",
        "    self.embedding = tf.keras.Layers.Embedding(vocab_size,model_size)\n",
        "    self.attention = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
        "    self.attention_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "\n",
        "        # num_layers FFN and Normalization layers\n",
        "    self.dense_1 = [tf.keras.layers.Dense(model_size * 4, activation='relu') for _ in range(num_layers)]\n",
        "    self.dense_2 = [tf.keras.layers.Dense(model_size) for _ in range(num_layers)]\n",
        "    self.ffn_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "\n",
        "  def call(self, sequence):\n",
        "        sub_in = []\n",
        "        for i in range(sequence.shape[1]):\n",
        "            # Compute the embedded vector\n",
        "            embed = self.embedding(tf.expand_dims(sequence[:, i], axis=1))\n",
        "            \n",
        "            # Add positional encoding to the embedded vector\n",
        "            sub_in.append(embed + pes[i, :])\n",
        "        \n",
        "        # Concatenate the result so that the shape is (batch_size, length, model_size)\n",
        "        sub_in = tf.concat(sub_in, axis=1)\n",
        "        \n",
        "        # We will have num_layers of (Attention + FFN)\n",
        "        for i in range(self.num_layers):\n",
        "            sub_out = []\n",
        "\n",
        "            # Iterate along the sequence length\n",
        "            for j in range(sub_in.shape[1]):\n",
        "                # Compute the context vector towards the whole sequence\n",
        "                attention = self.attention[i](\n",
        "                    tf.expand_dims(sub_in[:, j, :], axis=1), sub_in)\n",
        "\n",
        "                sub_out.append(attention)\n",
        "\n",
        "            # Concatenate the result to have shape (batch_size, length, model_size)\n",
        "            sub_out = tf.concat(sub_out, axis=1)\n",
        "\n",
        "            # Residual connection\n",
        "            sub_out = sub_in + sub_out\n",
        "            # Normalize the output\n",
        "            sub_out = self.attention_norm[i](sub_out)\n",
        "\n",
        "            # The FFN input is the output of the Multi-Head Attention\n",
        "            ffn_in = sub_out\n",
        "\n",
        "            ffn_out = self.dense_2[i](self.dense_1[i](ffn_in))\n",
        "            # Add the residual connection\n",
        "            ffn_out = ffn_in + ffn_out\n",
        "            # Normalize the output\n",
        "            ffn_out = self.ffn_norm[i](ffn_out)\n",
        "\n",
        "            # Assign the FFN output to the next layer's Multi-Head Attention input\n",
        "            sub_in = ffn_out\n",
        "            \n",
        "        # Return the result when done\n",
        "        return ffn_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW_4bP8egP5F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B3YC0M1gQBu"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, model_size, num_layers, h):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.model_size = model_size\n",
        "        self.num_layers = num_layers\n",
        "        self.h = h\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, model_size)\n",
        "        self.attention_bot = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
        "        self.attention_bot_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "        self.attention_mid = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
        "        self.attention_mid_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "        \n",
        "        self.dense_1 = [tf.keras.layers.Dense(model_size * 4, activation='relu') for _ in range(num_layers)]\n",
        "        self.dense_2 = [tf.keras.layers.Dense(model_size) for _ in range(num_layers)]\n",
        "        self.ffn_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
        "        \n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "    def call(self, sequence, encoder_output):\n",
        "        # EMBEDDING AND POSITIONAL EMBEDDING\n",
        "        embed_out = []\n",
        "        for i in range(sequence.shape[1]):\n",
        "            embed = self.embedding(tf.expand_dims(sequence[:, i], axis=1))\n",
        "            embed_out.append(embed + pes[i, :])\n",
        "            \n",
        "        embed_out = tf.concat(embed_out, axis=1)\n",
        "        \n",
        "        \n",
        "        bot_sub_in = embed_out\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            # BOTTOM MULTIHEAD SUB LAYER\n",
        "            bot_sub_out = []\n",
        "            \n",
        "            for j in range(bot_sub_in.shape[1]):\n",
        "                values = bot_sub_in[:, :j, :]\n",
        "                attention = self.attention_bot[i](\n",
        "                    tf.expand_dims(bot_sub_in[:, j, :], axis=1), values)\n",
        "\n",
        "                bot_sub_out.append(attention)\n",
        "            bot_sub_out = tf.concat(bot_sub_out, axis=1)\n",
        "            bot_sub_out = bot_sub_in + bot_sub_out\n",
        "            bot_sub_out = self.attention_bot_norm[i](bot_sub_out)\n",
        "            \n",
        "            # MIDDLE MULTIHEAD SUB LAYER\n",
        "            mid_sub_in = bot_sub_out\n",
        "\n",
        "            mid_sub_out = []\n",
        "            for j in range(mid_sub_in.shape[1]):\n",
        "                attention = self.attention_mid[i](\n",
        "                    tf.expand_dims(mid_sub_in[:, j, :], axis=1), encoder_output)\n",
        "\n",
        "                mid_sub_out.append(attention)\n",
        "\n",
        "            mid_sub_out = tf.concat(mid_sub_out, axis=1)\n",
        "            mid_sub_out = mid_sub_out + mid_sub_in\n",
        "            mid_sub_out = self.attention_mid_norm[i](mid_sub_out)\n",
        "\n",
        "            # FFN\n",
        "            ffn_in = mid_sub_out\n",
        "\n",
        "            ffn_out = self.dense_2[i](self.dense_1[i](ffn_in))\n",
        "            ffn_out = ffn_out + ffn_in\n",
        "            ffn_out = self.ffn_norm[i](ffn_out)\n",
        "\n",
        "            bot_sub_in = ffn_out\n",
        "        \n",
        "        logits = self.dense(ffn_out)\n",
        "            \n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcYWb_RJjNoi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa3Z3ak6gQEM"
      },
      "source": [
        "H = 2\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "encoder = Encoder(en_vocab_size, MODEL_SIZE, NUM_LAYERS, H)\n",
        "\n",
        "en_sequence_in = tf.constant([[1, 2, 3, 4, 6, 7, 8, 0, 0, 0], \n",
        "                           [1, 2, 3, 4, 6, 7, 8, 0, 0, 0]])\n",
        "encoder_output = encoder(en_sequence_in)\n",
        "\n",
        "print('Input vocabulary size', en_vocab_size)\n",
        "print('Encoder input shape', en_sequence_in.shape)\n",
        "print('Encoder output shape', encoder_output.shape)\n",
        "\n",
        "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "max_len_fr = data_fr_in.shape[1]\n",
        "decoder = Decoder(fr_vocab_size, MODEL_SIZE, NUM_LAYERS, H)\n",
        "\n",
        "fr_sequence_in = tf.constant([[1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0],\n",
        "                           [1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0]])\n",
        "decoder_output = decoder(fr_sequence_in, encoder_output)\n",
        "\n",
        "print('Target vocabulary size', fr_vocab_size)\n",
        "print('Decoder input shape', fr_sequence_in.shape)\n",
        "print('Decoder output shape', decoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHFohIUKjwYs"
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (data_en, data_fr_in, data_fr_out))\n",
        "dataset = dataset.shuffle(20).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PrRaBkjyaA"
      },
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True)\n",
        "\n",
        "\n",
        "def loss_func(targets, logits):\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG-hv0_4j0u_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKqD76XTjycE"
      },
      "source": [
        "@tf.function\n",
        "def train_step(source_seq, target_seq_in, target_seq_out):\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoder_output = encoder(source_seq)\n",
        "        \n",
        "        decoder_output = decoder(target_seq_in, encoder_output)\n",
        "\n",
        "        loss = loss_func(target_seq_out, decoder_output)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3Mh_H-1j35H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yey_U7zvj37d"
      },
      "source": [
        "def predict(test_source_text=None):\n",
        "    # If test sentence is not provided\n",
        "    # randomly pick up one from the training data\n",
        "    if test_source_text is None:\n",
        "        test_source_text = raw_data_en[np.random.choice(len(raw_data_en))]\n",
        "\n",
        "    print(test_source_text)\n",
        "    \n",
        "    # Tokenize the test sentence to obtain source sequence\n",
        "    test_source_seq = en_tokenizer.texts_to_sequences([test_source_text])\n",
        "    print(test_source_seq)\n",
        "\n",
        "    en_output = encoder(tf.constant(test_source_seq))\n",
        "\n",
        "    de_input = tf.constant([[fr_tokenizer.word_index['<start>']]], dtype=tf.int64)\n",
        "\n",
        "    out_words = []\n",
        "\n",
        "    while True:\n",
        "        de_output = decoder(de_input, en_output)\n",
        "        \n",
        "        # Take the last token as the predicted token\n",
        "        new_word = tf.expand_dims(tf.argmax(de_output, -1)[:, -1], axis=1)\n",
        "        out_words.append(fr_tokenizer.index_word[new_word.numpy()[0][0]])\n",
        "\n",
        "        # The next input is a new sequence\n",
        "        # contains both the input sequence and the predicted token\n",
        "        de_input = tf.concat((de_input, new_word), axis=-1)\n",
        "\n",
        "        # End if hitting <end> or length exceeds 14\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 14:\n",
        "            break\n",
        "\n",
        "    print(' '.join(out_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPS6DAsrj7Vz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FGX8nNej7Yj"
      },
      "source": [
        "NUM_EPOCHS = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for e in range(NUM_EPOCHS):\n",
        "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "        loss = train_step(source_seq, target_seq_in,\n",
        "                          target_seq_out)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(\n",
        "          e + 1, loss.numpy()))\n",
        "\n",
        "    if (e + 1) % 10 == 0:\n",
        "        end_time = time.time()\n",
        "        print('Average elapsed time: {:.2f}s'.format((end_time - start_time) / (e + 1)))\n",
        "        try:\n",
        "            predict()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}